{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> done loading network:\n",
      "> network contains 13460 nodes and 141296 links\n",
      "Network is NOT connected! Giant component taken.\n",
      "Got alpha=1.00 and as network: ../network_repository/allsmallnetworks/DataS1_interactome_ppi.txt.\n",
      "lcc network: #nodes=13329 , # edges=141150 \n",
      "Inversion done, with r== 0.9\n",
      "rnd walk computing time: 176.53\n",
      "\n",
      "> done reading gene sets:\n",
      "> 10 genes found\n",
      "number of genes in set: 10\n",
      "number of set genes on network: 10\n",
      "11261\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "26191\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "4772\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "260425\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "10666\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "3683\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "5771\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "9267\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "6776\n",
      "check for sum of initial p-vec\n",
      "0.0\n",
      "1437\n",
      "check for sum of initial p-vec\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# RANDOM WALK NEIGHBORHOOD OF TOP GENES\n",
    "#\n",
    "#\n",
    "# DOES NOT WORK RIGHT NOW\n",
    "#\n",
    "#\n",
    "#\n",
    "# input file: top genes \n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import networkx as nx\n",
    "import itertools as it\n",
    "import random as rd\n",
    "import pymysql\n",
    "import pickle \n",
    "import os.path\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import basic_network_things as bnt\n",
    "\n",
    "ID_symbol={}\n",
    "symbol_ID={}\n",
    "f=open('../data/symbols2entrezIDs.txt','r')\n",
    "for line in f:\n",
    "    if line[0]=='#':\n",
    "        continue\n",
    "    data      = line.strip().split('\\t')\n",
    "    symbol    = data[0]\n",
    "    ID        = data[1]\n",
    "    ID_symbol[ID]=symbol\n",
    "    symbol_ID[symbol]=ID\n",
    "f.close()\n",
    "\n",
    "#\n",
    "# define input files\n",
    "#\n",
    "#\n",
    "r=0.9 # restart probability\n",
    "alpha = 1\n",
    "infile = '../../IBD_paper/genes/top_10_genes_2019_nov_row_IDs.txt'\n",
    "network = '../network_repository/allsmallnetworks/DataS1_interactome_ppi.txt'\n",
    "def rnd_walk_matrix(A, r, alpha, num_nodes):\n",
    "    \n",
    "    n = num_nodes\n",
    "    M = normalize(A, norm='l1', axis=0)                                 # column wise normalized MArkov matrix\n",
    "    factor = float((1-alpha)/num_nodes)\n",
    "#     print(factor)\n",
    "    E = np.multiply(factor,np.ones([num_nodes,num_nodes]))              # prepare 2nd scaling term\n",
    "    M2 = np.multiply(alpha,M) + E                                       # mixture of Markov chains\n",
    "    del M\n",
    "    del E\n",
    "    \n",
    "    U = np.identity(n,dtype=int) \n",
    "    H = (1-r)*M2\n",
    "    H1 = np.subtract(U,H)\n",
    "    del U\n",
    "    del M2\n",
    "    del H    \n",
    "\n",
    "    W = r*np.linalg.inv(H1)                                             # calculate random-walk matrix\n",
    "    del H1\n",
    "    return W\n",
    "\n",
    "\n",
    "fnet = open(network, 'r')\n",
    "G0 = bnt.read_network(network)\n",
    "G = max(nx.connected_component_subgraphs(G0), key=len)\n",
    "if G.number_of_nodes() < G0.number_of_nodes():\n",
    "    print('Network is NOT connected! Giant component taken.')\n",
    "else:\n",
    "    print('Network is connected.')\n",
    "            \n",
    "fnet.close()\n",
    "print('Got alpha=%.2f and as network: %s.' %(alpha,network))\n",
    "# print('original network: #nodes=%s , # edges=%s ' %(G0.number_of_nodes(),G0.number_of_nodes()))\n",
    "print('lcc network: #nodes=%s , # edges=%s ' %(G.number_of_nodes(),G.number_of_edges()))\n",
    "\n",
    "# ###########################################################################\n",
    "#                                                                           #\n",
    "#    CALCULATES MATRIX INVERSION FOR GIVEN PARAMETERS                       #\n",
    "#                                                                           #\n",
    "# ###########################################################################\n",
    "num_nodes = G.number_of_nodes()                                             \n",
    "A = nx.adjacency_matrix(G, sorted(G.nodes()))\n",
    "t0 = time.time()\n",
    "W = rnd_walk_matrix(A, r, alpha, num_nodes)    \n",
    "print('Inversion done, with r== %s' %(r))    \n",
    "\n",
    "#    GENERATE DICT FOR NODE-LABELS TO INTEGERS\n",
    "d_idx_entz = {}                                                             #\n",
    "cc = 0                                                                      #\n",
    "for entz in sorted(G.nodes()):                                              #\n",
    "    d_idx_entz[cc] = entz                                                   #\n",
    "    cc += 1                                                                 #\n",
    "    d_entz_idx = dict((y,x) for x,y in d_idx_entz.items())                  #\n",
    "print('rnd walk computing time: %.2f' %float(time.time()-t0)) \n",
    "# LOAD EXTERNAL GENE SET\n",
    "geneset=bnt.read_gene_file_to_one(infile)\n",
    "print('number of genes in set: %s' %len(geneset))\n",
    "\n",
    "to_analyze=geneset&(G.nodes())\n",
    "print('number of set genes on network: %s' %len(to_analyze))\n",
    "for l_ent in to_analyze:\n",
    "    nodeset = l_ent\n",
    "    print(nodeset)\n",
    "    p0 = np.zeros(G.number_of_nodes())\n",
    "    # generate start vector\n",
    "    for n in range(len(p0)):\n",
    "        if n==nodeset:\n",
    "            p0[n] = 1.\n",
    "    print('check for sum of initial p-vec')\n",
    "    print(np.sum(p0))\n",
    "    pinf =  np.array(W.dot(p0))\n",
    "    \n",
    "    # DICT WITH NODE ID AND PVIS\n",
    "    d_n_p = {}\n",
    "    i = 0\n",
    "    for x in pinf[0]:\n",
    "        #     print(i,x)\n",
    "        d_n_p[d_idx_entz[i]] = x/1\n",
    "        i += 1\n",
    "    # write file\n",
    "    try:\n",
    "        sym1=ID_symbol[str(l_ent)]\n",
    "    except:\n",
    "        sym1=str(l_ent)\n",
    "        \n",
    "    outfile = '../../IBD_paper/rwr/from_TOP_genes/ppi_2015_r%s_%s.1f.txt' %(r,sym1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
